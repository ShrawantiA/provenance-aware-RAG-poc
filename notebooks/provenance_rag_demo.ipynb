# Provenance-aware RAG Demo
# Author: Shrawanti Anabattula

import hashlib
import pandas as pd
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# 1. Load sample data
data = pd.read_json("data/sample_logs.json")
docs = data["log_entry"].tolist()

# 2. Create embeddings and FAISS index
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(docs, embeddings)

# 3. Define provenance tagging function
def tag_provenance(text):
    return hashlib.sha256(text.encode()).hexdigest()

# 4. Retrieve & respond
qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model_name="gpt-4o-mini"),
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
)

query = "What anomalies occurred in network logs?"
result = qa({"query": query})
retrieved_docs = vectorstore.similarity_search(query, k=3)

# 5. Attach provenance tags
for doc in retrieved_docs:
    doc.metadata["provenance"] = tag_provenance(doc.page_content)

print("Response:", result["result"])
print("Provenance tags:", [d.metadata["provenance"] for d in retrieved_docs])
